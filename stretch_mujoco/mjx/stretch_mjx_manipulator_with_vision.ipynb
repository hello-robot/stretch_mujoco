{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBSdkbmGN2K-"
      },
      "source": [
        "# Stretch Mujoco Madrona-MJX Manipulator with Vision RL Training\n",
        "\n",
        "> Based on the Training Vision 2 tutorial by Google Deepmind: https://colab.research.google.com/github/google-deepmind/mujoco_playground/blob/main/learning/notebooks/training_vision_2.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNIJkb_FM2Ux"
      },
      "source": [
        "# Getting Started\n",
        "\n",
        "1. Run `uv venv && uv pip install -e .` at the root of the repo, to install all the normal dependencies\n",
        "2. Build [Madrona-MJX](https://github.com/shacklettbp/madrona_mjx/tree/main) from source by running:\n",
        "    ```\n",
        "    git clone https://github.com/shacklettbp/madrona_mjx.git\n",
        "\n",
        "    cd madrona_mjx\n",
        "    git submodule update --init --recursive\n",
        "    mkdir build\n",
        "    cd build\n",
        "    cmake -DLOAD_VULKAN=OFF ..\n",
        "    make -j\n",
        "\n",
        "    cd ..\n",
        "    uv pip install -e .\n",
        "    ```\n",
        "3. Run `uv pip install playground brax flax mediapy`\n",
        "\n",
        "The Deepmind team recommends a device with at least 24 GB VRAM, such as the RTX4090."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1Sy8ZRh3F-y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "madrona_repo_path = \"..\"\n",
        "\n",
        "os.environ[\"MADRONA_MWGPU_KERNEL_CACHE\"] = f\"{madrona_repo_path}/build/cache\"\n",
        "\n",
        "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\" # If you don't have the build cache, use this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ObF1UXrkb0Nd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shehab/Desktop/hellorobot/stretch_mujoco/.venv/lib/python3.13/site-packages/jaxopt/_src/osqp.py:299: SyntaxWarning: invalid escape sequence '\\m'\n",
            "  \"\"\"Operator Splitting Solver for Quadratic Programs.\n",
            "/Users/shehab/Desktop/hellorobot/stretch_mujoco/.venv/lib/python3.13/site-packages/ml_collections/config_dict/config_dict.py:163: SyntaxWarning: invalid escape sequence '\\['\n",
            "  index_match = re.match(\"(.*)\\[([0-9]+)\\]\", key)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mujoco_menagerie not found. Downloading...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning mujoco_menagerie: ██████████| 100/100 [00:16<00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking out commit 14ceccf557cc47240202f2354d684eca58ff8de4\n",
            "Successfully downloaded mujoco_menagerie\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import functools\n",
        "\n",
        "from brax.training.agents.ppo import networks_vision as ppo_networks_vision\n",
        "from brax.training.agents.ppo import train as ppo\n",
        "from flax import linen\n",
        "from IPython.display import clear_output\n",
        "import jax\n",
        "from jax import numpy as jp\n",
        "from matplotlib import pyplot as plt\n",
        "import mediapy as media\n",
        "import numpy as np\n",
        "\n",
        "from mujoco_playground import manipulation\n",
        "from mujoco_playground import wrapper\n",
        "from mujoco_playground._src.manipulation.franka_emika_panda import randomize_vision as randomize\n",
        "from mujoco_playground.config import manipulation_params\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wW16z3Ze3F-3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shehab/Desktop/hellorobot/stretch_mujoco/.venv/lib/python3.13/site-packages/mujoco_playground/_src/manipulation/franka_emika_panda/pick_cartesian.py:128: UserWarning: Madrona MJX not installed. Cannot use vision with PandaPickCubeCartesian.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "env_name = \"PandaPickCubeCartesian\"\n",
        "env_cfg = manipulation.get_default_config(env_name)\n",
        "\n",
        "num_envs = 1024\n",
        "episode_length = int(4 / env_cfg.ctrl_dt)\n",
        "\n",
        "# Rasterizer is less feature-complete than ray-tracing backend but stable\n",
        "config_overrides = {\n",
        "    \"episode_length\": episode_length,\n",
        "    \"vision\": True,\n",
        "    \"obs_noise.brightness\": [0.75, 2.0],\n",
        "    \"vision_config.use_rasterizer\": False,\n",
        "    \"vision_config.render_batch_size\": num_envs,\n",
        "    \"vision_config.render_width\": 64,\n",
        "    \"vision_config.render_height\": 64,\n",
        "    \"box_init_range\": 0.1, # +- 10 cm\n",
        "    \"action_history_length\": 5,\n",
        "    \"success_threshold\": 0.03\n",
        "}\n",
        "\n",
        "env = manipulation.load(env_name, config=env_cfg,\n",
        "                        config_overrides=config_overrides\n",
        ")\n",
        "randomization_fn = functools.partial(randomize.domain_randomize,\n",
        "                                        num_worlds=num_envs\n",
        ")\n",
        "env = wrapper.wrap_for_brax_training(\n",
        "    env,\n",
        "    vision=True,\n",
        "    num_vision_envs=num_envs,\n",
        "    episode_length=episode_length,\n",
        "    action_repeat=1,\n",
        "    randomization_fn=randomization_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmD819gf3F-3"
      },
      "source": [
        "#### Visualize the Environment\n",
        "\n",
        "To make our policy robust to differences between the simulation environment and reality, we randomize the colors of the background and the target as well as the camera pose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84G4BwPU3F-3"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)\n",
        "\n",
        "def tile(img, d):\n",
        "    assert img.shape[0] == d*d\n",
        "    img = img.reshape((d,d)+img.shape[1:])\n",
        "    return np.concat(np.concat(img, axis=1), axis=1)\n",
        "\n",
        "def unvmap(x):\n",
        "    return jax.tree.map(lambda y: y[0], x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-nVDKUQ3F-3"
      },
      "outputs": [],
      "source": [
        "state = jit_reset(jax.random.split(jax.random.PRNGKey(0), num_envs))\n",
        "media.show_image(tile(state.obs['pixels/view_0'][:64], 8), width=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWGK3kdL3F-4"
      },
      "source": [
        "To improve sample efficiency and facilitate real-world transfer, we use a cartesian action space in the y and z dimensions. This conditions out the underlying physics and removes the need for a stereo camera setup or depth sensor. We additionally discretize the gripper's action space so that it's fully opened or closed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPEhcsQk3F-4"
      },
      "outputs": [],
      "source": [
        "state = jit_reset(jax.random.split(jax.random.PRNGKey(0), num_envs))\n",
        "rollout = [unvmap(state)]\n",
        "\n",
        "f = 0.2\n",
        "for i in range(env_cfg.episode_length):\n",
        "  action = []\n",
        "  for j in range(env.action_size):\n",
        "    action.append(\n",
        "        jp.sin(\n",
        "            unvmap(state.data.time) * 2 * jp.pi * f + j * 2 * jp.pi / env.action_size\n",
        "        )\n",
        "    )\n",
        "  action = jp.tile(jp.array(action), (num_envs, 1))\n",
        "  state = jit_step(state, action)\n",
        "  rollout.append(unvmap(state))\n",
        "\n",
        "frames = env.render(rollout)\n",
        "media.show_video(frames, fps=1.0 / env.dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id7tvFja3F-4"
      },
      "source": [
        "## Train\n",
        "\n",
        "The policy trains in 7 min 4 sec on a RTX 4090 GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGQJeyX73F-4"
      },
      "outputs": [],
      "source": [
        "network_factory = functools.partial(\n",
        "    ppo_networks_vision.make_ppo_networks_vision,\n",
        "    policy_hidden_layer_sizes=[256, 256],\n",
        "    value_hidden_layer_sizes= [256, 256],\n",
        "    activation=linen.relu,\n",
        "    normalise_channels=True\n",
        ")\n",
        "\n",
        "ppo_params = manipulation_params.brax_vision_ppo_config(env_name)\n",
        "ppo_params.num_timesteps = 7_000_000\n",
        "ppo_params.num_envs = num_envs\n",
        "ppo_params.num_eval_envs = num_envs\n",
        "del ppo_params.network_factory\n",
        "ppo_params.network_factory = network_factory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIMpcsmw3F-4"
      },
      "outputs": [],
      "source": [
        "x_data, y_data, y_dataerr = [], [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  times.append(datetime.now())\n",
        "  x_data.append(num_steps)\n",
        "  y_data.append(metrics[\"eval/episode_reward\"])\n",
        "  y_dataerr.append(metrics[\"eval/episode_reward_std\"])\n",
        "\n",
        "  steps = ppo_params[\"num_timesteps\"]\n",
        "  plt.xlim([steps * -0.1, steps * 1.25])\n",
        "  plt.ylim([0, 14])\n",
        "  plt.xlabel(\"# environment steps\")\n",
        "  plt.ylabel(\"reward per episode\")\n",
        "  plt.title(f\"y={y_data[-1]:.3f}\")\n",
        "  plt.errorbar(x_data, y_data, yerr=y_dataerr, color=\"blue\")\n",
        "\n",
        "  display(plt.gcf())\n",
        "\n",
        "\n",
        "train_fn = functools.partial(\n",
        "    ppo.train,\n",
        "    augment_pixels=True,\n",
        "    **dict(ppo_params),\n",
        "    progress_fn=progress\n",
        ")\n",
        "\n",
        "make_inference_fn, params, metrics = train_fn(environment=env)\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "print(f\"time to train: {times[-1] - times[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAfItK7H3F-5"
      },
      "source": [
        "#### Visualize Policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4ySPLb83F-5"
      },
      "outputs": [],
      "source": [
        "jit_reset = jax.jit(env.reset)\n",
        "jit_step = jax.jit(env.step)\n",
        "jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "votR9SJE3F-5"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "rollout = []\n",
        "n_episodes = 1\n",
        "to_keep = 256\n",
        "\n",
        "def keep_until(state, i):\n",
        "    return jax.tree.map(lambda x: x[:i], state)\n",
        "\n",
        "for _ in range(n_episodes):\n",
        "    key_rng = jax.random.split(rng, num_envs)\n",
        "    state = jit_reset(key_rng)\n",
        "    rollout.append(keep_until(state, to_keep))\n",
        "    for i in range(env_cfg.episode_length):\n",
        "        act_rng, rng = jax.random.split(rng)\n",
        "        act_rng = jax.random.split(act_rng, num_envs)\n",
        "        ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "        state = jit_step(state, ctrl)\n",
        "        rollout.append(keep_until(state, to_keep))\n",
        "\n",
        "render_every = 1\n",
        "frames = env.render([unvmap(s) for s in rollout][::render_every])\n",
        "rewards = [unvmap(s).reward for s in rollout]\n",
        "media.show_video(frames, fps=1.0 / env.dt / render_every)\n",
        "plt.figure(figsize=(3, 2))\n",
        "plt.plot(rewards)\n",
        "plt.xlabel(\"time step\")\n",
        "plt.ylabel(\"reward\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA7IO5VD3F-5"
      },
      "source": [
        "As a finale, let's peek at some of the worlds our policy has been training in:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKs7LeyY3F-5"
      },
      "outputs": [],
      "source": [
        "obs = [np.array(s.obs['pixels/view_0']) for s in rollout]\n",
        "obs = [tile(img, int(np.sqrt(to_keep))) for img in obs]\n",
        "media.show_video(obs, fps=1.0/env_cfg.ctrl_dt, width=512)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
